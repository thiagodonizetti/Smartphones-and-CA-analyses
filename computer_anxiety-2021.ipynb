{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of smartphones and People with Computer Anxiety\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**Description:** Dataset containing metrics and scale results from field study performed at @CRECI. The study aims at supporting personalization features for people with Computer Anxiety (PwCA). The analyses use data from interaction logs to identify levels of Computer Anxiety (CA)\n",
    "\n",
    "**Goal:** Identify attributes to support regression for CARS values and classification using groups of PwCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imblearn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser('C:/Users/thiag/Documents/Doutorado/CHI 2021') ; # https://pypi.org/project/ipyfilechooser/\n",
    "display(fc)\n",
    "# /Users/vagsant/Documents/supervision/current/thiago santos/data/elementos-analise-video-graficos2.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fc.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xlsx = pd.ExcelFile( fc.selected ) ;\n",
    "df = pd.read_excel( xlsx, 'Todos os dados' ) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Age vs. CARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = df[df['CARS'] > 47]\n",
    "df_low = df[df['CARS'] < 34]\n",
    "df_moderate = df[df['CARS'] >= 34]\n",
    "df_moderate = df_moderate[df_moderate['CARS'] <= 47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( df_low )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( df_moderate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( df_high )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.scatter(df_low['Age'], df_low['CARS'],  label='Low CARS', norm=False)\n",
    "plt.scatter(df_moderate['Age'], df_moderate['CARS'],  label='Moderate CARS', norm=True)\n",
    "plt.scatter(df_high['Age'], df_high['CARS'],  label='High CARS', norm=True)\n",
    "ax.legend()\n",
    "plt.ylabel('CARS')\n",
    "plt.title('Age (years)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swtest, p_age = shapiro( df[ 'Age' ] )\n",
    "swtest, p_cars = shapiro( df[ 'CARS' ] )\n",
    "\n",
    "print( 'Shapiro-Wilk (Age) p-value: {:.5f}'.format( p_age ) ) \n",
    "print( 'Shapiro-Wilk (CARS) p-value: {:.5f}'.format( p_cars ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'Age'\n",
    "utest, p_lm = mannwhitneyu( df_low[ k ], df_moderate[ k ] )\n",
    "print(utest)\n",
    "utest, p_lh = mannwhitneyu( df_low[ k ], df_high[ k ] )\n",
    "print(utest)\n",
    "utest, p_mh = mannwhitneyu( df_moderate[ k ], df_high[ k ] )\n",
    "print(utest)\n",
    "\n",
    "print( 'Low CARS vs. Moderate CARS p-value {:.5f}'.format( p_lm ) ) \n",
    "print( 'Low CARS vs. High CARS p-value {:.5f}'.format( p_lh ) ) \n",
    "print( 'Moderate CARS vs. High CARS p-value {:.5f}'.format( p_mh ) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.boxplot([df_low['Age'], df_moderate['Age'], df_high['Age']])\n",
    "ax.legend()\n",
    "ax.set_xticklabels(['Low CARS', 'Moderate CARS', 'High CARS']) \n",
    "plt.ylabel('Age')\n",
    "plt.title('Age vs. CARS groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'STAI-T'\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.boxplot([df_low[k], df_moderate[k], df_high[k]])\n",
    "ax.legend()\n",
    "ax.set_xticklabels(['Low CARS', 'Moderate CARS', 'High CARS']) \n",
    "plt.ylabel(k)\n",
    "plt.title( k + ' vs. CARS groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'STAI-E'\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.boxplot([df_low[k], df_moderate[k], df_high[k]])\n",
    "ax.legend()\n",
    "ax.set_xticklabels(['Low CARS', 'Moderate CARS', 'High CARS']) \n",
    "plt.ylabel(k)\n",
    "plt.title( k + ' vs. CARS groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swtest, p_stai_t = shapiro( df[ 'STAI-T' ] )\n",
    "swtest, p_stai_e = shapiro( df[ 'STAI-E' ] )\n",
    "\n",
    "print( 'Shapiro-Wilk (STAI-T) p-value: {:.5f}'.format( p_stai_t ) ) \n",
    "print( 'Shapiro-Wilk (STAI-E) p-value: {:.5f}'.format( p_stai_e ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'STAI-T'\n",
    "utest, p_lm = mannwhitneyu( df_low[ k ], df_moderate[ k ] )\n",
    "utest, p_lh = mannwhitneyu( df_low[ k ], df_high[ k ] )\n",
    "utest, p_mh = mannwhitneyu( df_moderate[ k ], df_high[ k ] )\n",
    "\n",
    "print( 'Low CARS vs. Moderate CARS p-value {:.5f}'.format( p_lm ) ) \n",
    "print( 'Low CARS vs. High CARS p-value {:.5f}'.format( p_lh ) ) \n",
    "print( 'Moderate CARS vs. High CARS p-value {:.5f}'.format( p_mh ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'STAI-E'\n",
    "utest, p_lm = mannwhitneyu( df_low[ k ], df_moderate[ k ] )\n",
    "utest, p_lh = mannwhitneyu( df_low[ k ], df_high[ k ] )\n",
    "utest, p_mh = mannwhitneyu( df_moderate[ k ], df_high[ k ] )\n",
    "\n",
    "print( 'Low CARS vs. Moderate CARS p-value {:.5f}'.format( p_lm ) ) \n",
    "print( 'Low CARS vs. High CARS p-value {:.5f}'.format( p_lh ) ) \n",
    "print( 'Moderate CARS vs. High CARS p-value {:.5f}'.format( p_mh ) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a classifier after resampling CARS groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Time(sec)\n",
    "# Clicks Number\n",
    "# DB Clicks Number\n",
    "# MEAN CLICK DURATION (sec)\n",
    "# TYPING VELOCITY (key/min)\n",
    "# TOTAL TIME TYPING (sec)\n",
    "\n",
    "X = df.iloc[:, [14, 21, 22, 23, 32, 33] ] # Columns that could be recorded in a mobile seting\n",
    "y = df['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "print ( len( y_over ) )\n",
    "X_over, y_over = oversample.fit_resample(X_over, y_over)\n",
    "print ( len( y_over ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_over = classifier.predict(X_test_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_over == y_pred_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_over, y_pred_over)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = classifier, X = X_train_over, y = y_train_over, cv = 3)\n",
    "print( accuracies.mean() )\n",
    "print( accuracies.std() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a regressor for CARS values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "# Columns\n",
    "# Age\n",
    "# Education Levels (years)\n",
    "# Minimental\n",
    "# GDS\n",
    "# CSE\n",
    "# STAI-T\n",
    "# STAI-E\n",
    "# SUS\n",
    "# Minimental - Result\n",
    "# GDS - Result\n",
    "# Aproved\n",
    "# Task Completion\n",
    "# Task End\n",
    "# Task Time(sec)\n",
    "# Events Number\n",
    "# Nodes Number\n",
    "# Eccentricity\n",
    "# Incidentes Number\n",
    "# Mean Degree\n",
    "# MOUSE DOWN-UP\n",
    "# Clicks Number\n",
    "# DB Clicks Number\n",
    "# MEAN CLICK DURATION (sec)\n",
    "# MEAN PAUSE BEFORE CLICK (sec)\n",
    "# MOUSE TOTAL DISTANCE (px)\n",
    "# MOUSE MEAN DISTANCE (px)\n",
    "# MOUSE MEAN VELOCITY (px/sec)\n",
    "# MEAN STROKE LENGTH (px)\n",
    "# MEAN STROKE DURATION (sec)\n",
    "# MEAN STRAIGHTNESS\n",
    "# KEYS\n",
    "# TYPING VELOCITY (key/min)\n",
    "# TOTAL TIME TYPING (sec)\n",
    "# MEAN TIME TYPING (sec)\n",
    "# DELETE\n",
    "# BACKSPACE\n",
    "# DELETE + BACKSPACE\n",
    "# Gaze Total Distance (px)\n",
    "# Gaze Mean Distance (px)\n",
    "# Gaze Total Time (sec)\n",
    "# Gaze Velocity (px/s)\n",
    "# Mean Pupil Size (norm)\n",
    "# Pupil standard deviation (norm)\n",
    "# High Three Sigma\n",
    "# Low three sigma\n",
    "# High Outliers\n",
    "# Low Outliers\n",
    "# CARS\n",
    "\n",
    "\n",
    "# X = df.iloc[:, 1:47]\n",
    "# X = X.drop( columns = ['Minimental - Result', 'GDS - Result', 'Aproved', 'Task Completion', 'Task End'] )\n",
    "\n",
    "# X = df.iloc[:, 1:9]\n",
    "# X = df.iloc[:, 21:25]\n",
    "X = df.iloc[:, [14, 21, 22, 23, 32, 33] ] # Columns that could be recorded in a mobile seting\n",
    "y = df['CARS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding good n_estimators\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "i = 10\n",
    "mse = 100**100\n",
    "n_estimators = i\n",
    "r2 = 0.0\n",
    "while i < 10000:\n",
    "    regressor = RandomForestRegressor(n_estimators = i, random_state = 0)\n",
    "    regressor.fit(X, y)\n",
    "    y_pred = regressor.predict(X)\n",
    "    print( 'R2: ' + str( r2_score(y, y_pred ) ) + '\\tn_estimators = ' + str( i ) + '\\tMSE = ' + str( mean_squared_error(y, y_pred) ) )\n",
    "    if( mean_squared_error(y, y_pred) < mse ):\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        n_estimators = i\n",
    "        r2 = r2_score( y, y_pred )\n",
    "    i = i * 2\n",
    "    \n",
    "print( '--> Best n_estimators=' + str( n_estimators ) + ' with MSE=' + str( mse ) + ' and R2=' + str( r2 ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators = n_estimators, random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X)\n",
    "y - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Random Forest Regression results (higher resolution)\n",
    "padding = 10\n",
    "min_y = min( min( y ), min( y_pred ) ) - padding\n",
    "max_y = max( max( y ), max( y_pred ) ) + padding\n",
    "plt.figure( figsize = ( 20, 10 ) ) ;\n",
    "plt.scatter( y, regressor.predict(X), c = abs( y_pred - y ), alpha = 1.0, cmap=plt.cm.get_cmap('RdYlGn_r'))\n",
    "plt.plot( list( range( min_y, max_y) ), list( range( min_y, max_y) ), color = 'green' ) \n",
    "plt.xlim( min_y, max_y )\n",
    "plt.ylim( min_y, max_y )\n",
    "plt.title('Random Forest Regression')\n",
    "plt.xlabel('CARS')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buliding a regressor after over resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Time(sec)\n",
    "# Clicks Number\n",
    "# DB Clicks Number\n",
    "# MEAN CLICK DURATION (sec)\n",
    "# TYPING VELOCITY (key/min)\n",
    "# TOTAL TIME TYPING (sec)\n",
    "\n",
    "X = df.iloc[:, [14, 21, 22, 23, 32, 33] ] # Columns that could be recorded in a mobile seting\n",
    "y = df['CARS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len( y ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "size = len( y_over )\n",
    "prev_size = 0\n",
    "while size > prev_size:\n",
    "    prev_size = size \n",
    "    X_over, y_over = oversample.fit_resample(X_over, y_over) # must be only resample after previous fit\n",
    "    size = len( y_over )\n",
    "    print( size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist( y_over )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform( X_train_over )\n",
    "X_test = sc.transform( X_test_over )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding good n_estimators\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "i = 10\n",
    "mse = 100**100\n",
    "n_estimators = i\n",
    "r2 = 0.0\n",
    "while i < 10000:\n",
    "    regressor = RandomForestRegressor(n_estimators = i, random_state = 0)\n",
    "    regressor.fit(X_train_over, y_train_over)\n",
    "    y_pred = regressor.predict(X_test_over)\n",
    "    print( 'R2: ' + str( r2_score(y_test_over, y_pred ) ) + '\\tn_estimators = ' + str( i ) + '\\tMSE = ' + str( mean_squared_error(y_test_over, y_pred) ) )\n",
    "    if( mean_squared_error(y_test_over, y_pred) < mse ):\n",
    "        mse = mean_squared_error(y_test_over, y_pred)\n",
    "        n_estimators = i\n",
    "        r2 = r2_score( y_test_over, y_pred )\n",
    "    i = i * 2\n",
    "    \n",
    "print( '--> Best n_estimators=' + str( n_estimators ) + ' with MSE=' + str( mse ) + ' and R2=' + str( r2 ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor = RandomForestRegressor(n_estimators = i, random_state = 0)\n",
    "#print('i = ' + str(i) + 'best i '+ str( n_estimators ) )\n",
    "regressor = RandomForestRegressor(n_estimators = n_estimators, random_state = 0)\n",
    "regressor.fit(X_train_over, y_train_over)\n",
    "y_pred = regressor.predict(X_test_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs( y_test_over - y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualising the Random Forest Regression results (higher resolution)\n",
    "padding = 10\n",
    "min_y = min( min( y_test_over ), min( y_pred ) ) - padding\n",
    "max_y = max( max( y_test_over ), max( y_pred ) ) + padding\n",
    "plt.figure( figsize = ( 20, 10 ) ) ;\n",
    "# plt.scatter( y_test_over, regressor.predict(X_test_over), c = abs( y_pred - y_test_over ), alpha = 1.0, cmap=plt.cm.get_cmap('RdYlGn_r'))\n",
    "plt.scatter( y_test_over, regressor.predict(X_test_over), c = 'green')\n",
    "plt.plot( list( range( min_y, max_y) ), list( range( min_y, max_y) ), color = 'green' ) \n",
    "plt.xlim( min_y, max_y )\n",
    "plt.ylim( min_y, max_y )\n",
    "plt.title('Random Forest Regression')\n",
    "plt.xlabel('CARS')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, [14, 21, 22, 23, 32, 33] ] # Columns that could be recorded in a mobile seting\n",
    "y = df['CLASS']\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "size = len( y_over )\n",
    "prev_size = 0\n",
    "while size > prev_size:\n",
    "    prev_size = size \n",
    "    X_over, y_over = oversample.fit_resample(X_over, y_over) # must be only resample after previous fit\n",
    "    size = len( y_over )\n",
    "    print( size )\n",
    "    \n",
    "    \n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(X_over, y_over, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform( X_train_over )\n",
    "X_test = sc.transform( X_test_over )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "\n",
    "import os     \n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree = dtree.fit(X_train_over, y_train_over)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#y_pred2 = dtree.predict(X_test_over)\n",
    "#dtree.score(y_pred2, y_pred2)\n",
    "score1 = dtree.score(X_test_over, y_test_over)\n",
    "score2 = dtree.score(X_train_over, y_train_over)\n",
    "score3 = dtree.score(X, y)\n",
    "\n",
    "print(\"Score 1 \", score1)\n",
    "print(\"Score 2 \", score2)\n",
    "print(\"Score 3 \", score3)\n",
    "\n",
    "\n",
    "#new_series = pd.Series(y_pred2)\n",
    "#print(new_series)\n",
    "\n",
    "\n",
    "#abs( y_test_over - y_pred2 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X.columns\n",
    "\n",
    "data = tree.export_graphviz(dtree, out_file=None, feature_names=col_names,filled=True, rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(data)\n",
    "graph.set_size('\"20,20!\"')\n",
    "graph.write_png('decisionTree.png')\n",
    "\n",
    "graph.write_png('resized_tree.png')\n",
    "\n",
    "\n",
    "\n",
    "img=pltimg.imread('resized_tree.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "import graphviz\n",
    "gvz_graph = graphviz.Source(graph.to_string())\n",
    "gvz_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = dtree.predict(X_test_over)\n",
    "# Visualising the Random Forest Regression results (higher resolution)\n",
    "padding = 10\n",
    "min_y = min( min( y_test_over ), min( yp ) ) - padding\n",
    "max_y = max( max( y_test_over ), max( yp ) ) + padding\n",
    "plt.figure( figsize = ( 20, 10 ) ) ;\n",
    "# plt.scatter( y_test_over, regressor.predict(X_test_over), c = abs( y_pred - y_test_over ), alpha = 1.0, cmap=plt.cm.get_cmap('RdYlGn_r'))\n",
    "plt.scatter( y_test_over, lreg.predict(X_test_over), c = 'green')\n",
    "plt.plot( list( range( min_y, max_y) ), list( range( min_y, max_y) ), color = 'green' ) \n",
    "plt.xlim( min_y, max_y )\n",
    "plt.ylim( min_y, max_y )\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('CARS')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the linear regressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#regressor.fit(X_train_over, y_train_over)\n",
    "#y_pred = regressor.predict(X_test_over)\n",
    "\n",
    "#print(X_test_over)\n",
    "#print(y_test_over)\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_over, y_train_over) \n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = lreg.predict(X_test_over)\n",
    "#print(\"yy \", len(y_pred))\n",
    "#print(\"xx \", len(X_test_over))\n",
    "\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', lreg.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test_over, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test_over, y_pred))\n",
    "\n",
    "\n",
    "scor = lreg.score(X_train_over, y_train_over)\n",
    "print(\"score \", scor)\n",
    "#yp = lreg.predict(X_test_over)\n",
    "#print(\"yp \",yp )\n",
    "\n",
    "\n",
    "#abs( y_test_over - yp )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Random Forest Regression results (higher resolution)\n",
    "padding = 10\n",
    "min_y = min( min( y_test_over ), min( yp ) ) - padding\n",
    "max_y = max( max( y_test_over ), max( yp ) ) + padding\n",
    "plt.figure( figsize = ( 20, 10 ) ) ;\n",
    "# plt.scatter( y_test_over, regressor.predict(X_test_over), c = abs( y_pred - y_test_over ), alpha = 1.0, cmap=plt.cm.get_cmap('RdYlGn_r'))\n",
    "plt.scatter( y_test_over, lreg.predict(X_test_over), c = 'green')\n",
    "plt.plot( list( range( min_y, max_y) ), list( range( min_y, max_y) ), color = 'green' ) \n",
    "plt.xlim( min_y, max_y )\n",
    "plt.ylim( min_y, max_y )\n",
    "plt.title('Linear Regression')\n",
    "plt.xlabel('CARS')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2, random_state=0)\n",
    "clf.fit(X_train_over, y_train_over) \n",
    "\n",
    "\n",
    "test_pred_decision_tree = clf.predict(X_test_over)\n",
    "metrics.accuracy_score(y_test_over, test_pred_decision_tree)\n",
    "\n",
    "#y_pred = clf.predict(X_test_over)\n",
    "#abs( y_test_over - yp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#print(X)\n",
    "#print(y)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train_over, y_train_over) \n",
    "\n",
    "\n",
    "test_pred_decision_tree = clf.predict(X_test_over)\n",
    "metrics.accuracy_score(y_test_over, test_pred_decision_tree)\n",
    "\n",
    "#y_pred = clf.predict(X_test_over)\n",
    "#abs( y_test_over - yp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
